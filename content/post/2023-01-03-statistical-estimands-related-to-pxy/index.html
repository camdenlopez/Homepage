---
title: "Statistical estimands related to P(X>Y)"
author: "Camden Lopez"
date: "2023-01-03"
slug: statistical-estimands-related-to-pxy
categories: []
tags: []
---



<p>Since posting about the area under the ROC curve and “concordance probability” as a potential measure of treatment effect, I’ve wanted to better understand the history and current state of this idea. To what extent have statisticians investigated this measure and developed methodology around it? To what extent has the “concordance probability” been used in practice? Are there reasons why it hasn’t been more widely used?</p>
<p>This is a summary of literature on <span class="math inline">\(\text{P}(X &gt; Y)\)</span> as a measure for comparing two population distributions and quantifying treatment effect. By <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>, I mean random outcomes from the two populations being compared (e.g. <span class="math inline">\(X\)</span> = outcome for a patient treated with an experimental treatment, and <span class="math inline">\(Y\)</span> = outcome for a patient receiving a control treatment). I found that several related quantities have been proposed, and I include references about those.</p>
<p>Searching the literature for this topic has been a little difficult because there’s no single term used consistently for <span class="math inline">\(\text{P}(X &gt; Y)\)</span> (some authors don’t even attempt to name it). I suspect there are still important references out there that I haven’t found yet, and if so, I’ll keep adding to this post.</p>
<div id="pxy-and-pxy-½-pxy" class="section level1">
<h1>P(X&gt;Y) and P(X&gt;Y) + ½ P(X=Y)</h1>
<p><strong>Gini, C. (1916), “Il concetto di ‘transvariazione’ e le sue prime applicazioni,” <em>Giornale degli Economisti e Rivista di Statistica</em>, 53, 13–43.</strong> According to Kruskal,<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a> Gini proposed a quantity equivalent to <span class="math inline">\(\text{P}(X &gt; Y) + \frac{1}{2} \text{P}(X = Y)\)</span> which he called the <em>probability of transvariation</em>. I haven’t actually accessed Gini’s paper (and wouldn’t be able to read the Italian).</p>
<p><strong>Ottaviani, G. (1939), “Sulla probabilità che una prova su due variabili casuali <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> verifichi la disuguaglianza <span class="math inline">\(X&lt;Y\)</span> e sul corrispondente scarto quadratico medio,” <em>Giornale dell’ Istituto Italiano degli Attuari</em>, 10, 186–192.</strong> Again according to Kruskal,<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a> Ottaviani wrote about estimation of <span class="math inline">\(\text{P}(X &gt; Y)\)</span> using <span class="math inline">\(\frac{U}{mn}\)</span>. Here I use <span class="math inline">\(U\)</span> to refer to the statistic that Mann and Whitney (1947) would later propose.</p>
<p><strong>Wilcoxon, F. (1945), “Individual comparisons by ranking methods,” <em>Biometrics Bulletin</em>, 1(6), 80–83.</strong> Proposed the rank-sum test for two-sample comparison but didn’t specify the statistical hypotheses being tested or a parameter that might be estimated. Ties were handled by assigning an average rank to each outcome in a group of tied outcomes. The rank-sum test is still one of the most common non-parametric tests, and it was a basis for development of hypothesis testing and estimation for <span class="math inline">\(\text{P}(X &gt; Y)\)</span>.</p>
<p><strong>Mann, H. B., and Whitney, D. R. (1947), “On a test of whether one of two random variables is stochastically larger than the other,” <em>Annals of Mathematical Statistics</em>, 18(1), 50–60.</strong> Proposed specific hypotheses to be tested by a Wilcoxon-inspired, rank-based test: a null hypothesis of equal cdfs between two populations, and an alternative of one population cdf being stochastically larger, i.e. <span class="math inline">\(F_X(z) &gt; F_Y(z)\)</span> for all <span class="math inline">\(z\)</span>. The test statistic was <span class="math inline">\(U\)</span>, the number of pairs <span class="math inline">\((x_i, y_j)\)</span> for which <span class="math inline">\(x_i &gt; y_j\)</span> among all pairs of an outcome from one sample (<span class="math inline">\(x_i\)</span>) with an outcome from the other (<span class="math inline">\(y_j\)</span>). It was assumed that no ties occur. A simple formula relates <span class="math inline">\(U\)</span> to Wilcoxon’s rank-sum statistic. Still no parameter was identified — the only interest was in hypothesis testing.</p>
<p><strong>Birnbaum, Z. W. (1956), “On a use of the Mann-Whitney statistic,” <em>Proceedings of the Third Berkeley Symposium on Mathematical Statistics and Probability</em>, 1, 13–17.</strong> Gave attention to <span class="math inline">\(p = \text{P}(X &gt; Y)\)</span> as a parameter one might want to estimate — for example, in evaluating the reliability of mechanical components. Considered estimation of <span class="math inline">\(p\)</span> using <span class="math inline">\(\hat{p} = \frac{U}{mn}\)</span>, the Mann-Whitney statistic divided by the number of pairs in the sample, and construction of confidence intervals when one can’t rely on large-sample normality.</p>
<p><strong>Klotz, J. H. (1966), “The Wilcoxon, ties, and the computer,” <em>Journal of the American Statistical Association</em>, 61(315), 772–787.</strong> Suggested <span class="math inline">\(\text{P}(X &gt; Y) + \frac{1}{2} \text{P}(X = Y)\)</span> as a reasonable measure of the degree of separation of two distributions, in the context of discussing the null distribution for the Wilcoxon (Mann-Whitney) test.</p>
<p><strong>Wolfe, D. A. and Hogg, R. V. (1971), “On constructing statistics and reporting data,” <em>The American Statistician</em>, 25(4), 27–30.</strong> Suggested that <span class="math inline">\(\text{P}(X &gt; Y)\)</span> is a measure for comparing two distributions that is widely applicable and more immediately interpretable than, for example, <span class="math inline">\((\mu_2 - \mu_1) / \sigma\)</span>. Showed how <span class="math inline">\(\text{P}(X &gt; Y)\)</span> can be a basis for common statistical comparisons and tests, both parametric and non-parametric.</p>
<p><strong>Hand, D. J. (1992), “On comparing two treatments,” <em>The American Statistician</em>, 46(3), 190–192.</strong> Noting that 1) the probability that an individual will have a better outcome from treatment A than treatment B, <span class="math inline">\(\text{P}(z_A - z_B &gt; 0)\)</span>, is a sensible measure of treatment effect, and 2) in some situations it’s feasible only to estimate the probability that an individual treated with A will have a better outcome than an independently sampled individual treated with B, <span class="math inline">\(\text{P}(x_A - y_B &gt; 0)\)</span>; considered when those two parameters can be qualitatively opposite (one indicating treatment benefit, the other indicating harm).</p>
<p><strong>McGraw, K. O. and Wong, S. P. (1992), “A common language effect size statistic,” <em>Psychological Bulletin</em>, 111(2), 361–365.</strong> Proposed using <span class="math inline">\(\text{P}(X &gt; Y)\)</span>, which they term <em>CL</em>, as a measure of effect size, writing that it “is so readily understood by nonstatisticians that we have chosen to call it the <em>common language effect size</em> indicator.” Echoing Wolfe and Hogg (1971), they considered <em>CL</em> more readily interpretable than Cohen’s <em>d</em> (a standardized mean difference) and several other effect size indicators.</p>
<p><strong>Grissom, R. J. (1994), “Probability of the superior outcome of one treatment over another,” <em>Journal of Applied Psychology</em>, 79(2), 314–316.</strong> Cited Wolfe and Hogg (1971), and McGraw and Wong (1992), but suggested calling <span class="math inline">\(\text{P}(X &gt; Y)\)</span> the <em>probability of superiority</em> (<em>PS</em>).</p>
<p><strong>Hauck, W. W., Hyslop, T., and Anderson, S. (2000), “Generalized treatment effects for clinical trials,” <em>Statistics in Medicine</em>, 19, 887–899.</strong> Drawing inspiration from a paper<a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a> about improving two-sample comparisons, suggested <span class="math inline">\(\text{P}(X &gt; Y)\)</span> specifically as the target parameter for assessing treatment effects in clinical trials. Noted that it’s easily understood by clinical, non-statistical colleagues.</p>
<p><strong>Vargha, A., and Delaney, H. D. (2000), “A critique and improvement of the ‘CL’ common language effect size statistics of McGraw and Wong,” <em>Journal of Educational and Behavioral Statistics</em>, 25(2), 101–132.</strong> Commenting on McGraw and Wong’s (1992) proposal of <em>CL</em> = <span class="math inline">\(\text{P}(X &gt; Y)\)</span> as an effect size metric, Vargha and Delaney suggested <span class="math inline">\(\text{P}(X &gt; Y) + \frac{1}{2} \text{P}(X = Y)\)</span> instead, denoting it <em>A</em> and naming it the <em>measure of stochastic superiority</em>. They wrote, “If [the outcome] is discrete], <em>A</em> can be interpreted as an estimate of the value of <em>CL</em> that would be obtained if the distribution of [the outcome] were continuous.”</p>
<p><strong>Acion, L., Peterson, J. J., Temple, S., and Arndt, S. (2006), “Probabilistic index: an intuitive non-parametric approach to measuring the size of treatment effects,” <em>Statistics in Medicine</em>, 25, 591–602.</strong> Yet another proposal to use the “probabilistic index” <span class="math inline">\(\text{P}(X &gt; Y)\)</span> as an intuitive measure of treatment effect. Described calculating <span class="math inline">\(\hat{\text{P}}(X &gt; Y)\)</span> in a manner that actually would estimate <span class="math inline">\(\text{P}(X &gt; Y) + \frac{1}{2} \text{P}(X = Y)\)</span>.</p>
<p><strong>Senn, S. (2006), “Probabilistic index: an intuitive non-parametric approach to measuring the size of treatment effects” (Letter to the Editor), <em>Statistics in Medicine</em>, 25, 3944–3946.</strong> Argued that <span class="math inline">\(\text{P}(X &gt; Y)\)</span> and related measures of treatment effect are difficult for a clinician to understand and explain, with <span class="math inline">\(\text{P}(X &gt; Y)\)</span> being easily mistaken for the probability of benefit; and are not “robust” or clinically meaningful because they depend on “nuisance parameters” such as variance and covariance, and on measurement error. In particular, argued that outcome variance observed in a clinical trial is unlikely to represent the variance in the target population. These arguments were given again, more fully, elsewhere.<a href="#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a> This is the only objection to <span class="math inline">\(\text{P}(X &gt; Y)\)</span> as a measure of treatment effect that I’ve seen.</p>
<p><strong>Agresti, A. (2010), <em>Analysis of Ordinal Categorical Data</em> (2nd ed.), Hoboken, NJ: John Wiley and Sons.</strong> Used <span class="math inline">\(\alpha\)</span> to denote the “stochastic superiority” measure <span class="math inline">\(\alpha = \text{P}(X &gt; Y) + \frac{1}{2} \text{P}(X = Y)\)</span> in the setting of an ordinal outcome compared between two groups, giving credit to Vargha and Delaney<a href="#fn5" class="footnote-ref" id="fnref5"><sup>5</sup></a> for the term <em>stochastic superiority</em> (p. 13–14). Cites other non-parametric statistics literature that uses <span class="math inline">\(\alpha\)</span> (p. 41).</p>
<p><strong>Kieser, M., Friede, T., and Gondan, M. (2013), “Assessment of statistical significance and clinical relevance,” <em>Statistics in Medicine</em>, 32, 1707–1719.</strong> In the context of bringing attention to the need for assessing not only statistical significance but also clinical significance in clinical trials, and noting problems with “responder analysis” which uses a threshold for defining a desirable outcome, recommended the “relative effect” <span class="math inline">\(\theta = \text{P}(X &gt; Y) + \frac{1}{2} \text{P}(X = Y)\)</span>.</p>
<p><strong>Demidenko, E. (2016), “The <span class="math inline">\(p\)</span>-value you can’t buy,” <em>The American Statistician</em>, 70(1), 33–38.</strong> Reviewed some criticism of <span class="math inline">\(p\)</span>-values and — stating that “the root of the problem with the <span class="math inline">\(p\)</span>-value is the group mean comparison” — recommended the “<span class="math inline">\(D\)</span>-value” (or its complement, the “<span class="math inline">\(B\)</span>-value”), the empirical estimate of <span class="math inline">\(\delta = \text{P}(X &gt; Y)\)</span>. Greenland et al.<a href="#fn6" class="footnote-ref" id="fnref6"><sup>6</sup></a> published a strongly worded criticism of Demidenko, primarily because of his statement that “the <span class="math inline">\(D\)</span>-value is the proportion of patients who got worse after the treatment.” Greenland et al. interpret this as Demidenko mistaking <span class="math inline">\(\text{P}(X &gt; Y)\)</span> for <span class="math inline">\(\text{P}[Y(1) &gt; Y(0)]\)</span> (or assuming that they were equal). To me, it’s not clear what Demidenko meant, or why he phrased his statement that way — and the criticism seems a little harsh. The phrase “patients who got worse” is strange because it seems to refer to the patient’s state improving or declining over time, which involves neither comparison with another patient nor comparison with this same patient’s counterfactual outcome under a comparison treatment. Meanwhile, Demidenko correctly describes the meaning of what he calls the <span class="math inline">\(D\)</span>-value elsewhere in the paper.</p>
<p><strong>Fay, M. P., Brittain, E. H., Shih, J. H., Follman, D. A., and Gabriel, E. E. (2018), “Causal estimands and confidence intervals associated with Wilcoxon‐Mann‐Whitney tests in randomized experiments,” <em>Statistics in Medicine</em>, 37, 2923–2937.</strong> Denoted the “Mann-Whitney parameter” <span class="math inline">\(\phi = \text{P}(X &gt; Y) + \frac{1}{2}\text{P}(X = Y)\)</span> and contrasted it with <span class="math inline">\(\psi = \text{P}[Y(1) &gt; Y(0)] + \frac{1}{2}\text{P}[Y(1) = Y(0)]\)</span>, where <span class="math inline">\(Y(t)\)</span> is the potential outcome for a patient given treatment <span class="math inline">\(t\)</span>. Reviewed “Hand’s paradox” (1992) in which <span class="math inline">\(\phi &gt; \frac{1}{2}\)</span> but <span class="math inline">\(\psi &lt; \frac{1}{2}\)</span> or vice-versa, and described some results about bounding <span class="math inline">\(\psi\)</span>.</p>
</div>
<div id="pxy-pyx-and-pxy-pyx-pxy" class="section level1">
<h1>P(X&gt;Y) – P(Y&gt;X) and [P(X&gt;Y) – P(Y&gt;X)] / P(X≠Y)</h1>
<p><strong>Deuchler, G. (1914), “Über die Methoden der Korrelationsrechnung in der Pädagogik und Psychologie,” <em>Zeitschrift für Pädagogische Psychologie und Experimentelle Pädagogik</em>, 15, 114–131, 145–159, 229–242.</strong> According to Kruskal,<a href="#fn7" class="footnote-ref" id="fnref7"><sup>7</sup></a> Deuchler suggested a method for comparing two samples that was essentially equivalent to the Wilcoxon rank-sum test. The test statistic could be considered a sample estimate of <span class="math inline">\(\frac{\text{P}(X&gt;Y) - \text{P}(Y&gt;X)}{\text{P}(X \ne Y)}\)</span>.</p>
<p><strong>Kendall, M. G. (1938), “A new measure of rank correlation,” <em>Biometrika</em>, 30(1/2), 81–93.</strong> Proposed the correlation metric <span class="math inline">\(\tau\)</span> which was a predecessor of — and is similar to — Goodman and Kruskal’s <span class="math inline">\(\gamma\)</span> (1954).</p>
<p><strong>Goodman, L. A., and Kruskal, W. H. (1954), “Measure of association for cross classifications,” <em>Journal of the American Statistical Association</em>, 49(268), 732–764.</strong> Proposed a measure of association between two ordinal variables, <span class="math inline">\(\gamma = \frac{\Pi_s - \Pi_d}{1 - \Pi_t}\)</span>. <span class="math inline">\(\Pi_s\)</span> is the probability that, in a random pair of individuals from a population, the comparison of measurements of one variable will agree with the comparison of measurements of the other variable; in other words, either individual 1 has the greater value in both variables, or individual 2 has the greater value in both variables. <span class="math inline">\(\Pi_d\)</span> is the probability that the comparison for one variable disagrees with the comparison of the other; <span class="math inline">\(\Pi_t\)</span> is the probability of a tie in either variable. The same measure <span class="math inline">\(\gamma\)</span> could be used for comparison of two population distributions by measuring the “correlation” of membership in one population (vs the other) with an ordinal outcome variable. Allowing the outcome to be continuous is another simple extension.</p>
<p><strong>Simonoff, J. S., Hochberg, Y., and Reiser, B. (1986), “Alternative estimation procedures for Pr(X &lt; Y) in categorized data,” <em>Biometrics</em>, 42, 895–907.</strong> Considered <span class="math inline">\(\text{P}(X &gt; Y)\)</span> to be an important estimand, but suggested estimating <span class="math inline">\(\lambda = \text{P}(X &gt; Y) - \text{P}(Y &gt; X)\)</span> instead when <span class="math inline">\(\text{P}(X = Y) &gt; 0\)</span>.</p>
<p><strong>Cliff, N. (1993), “Dominance statistics: Ordinal analyses to answer ordinal questions,” <em>Psychological Bulletin</em>, 114(3), 494–509.</strong> Argued for use of ordinal methods in behavioral science, and suggested focusing on <span class="math inline">\(\delta = \text{P}(X &gt; Y) - \text{P}(Y &gt; X)\)</span>. Considered <span class="math inline">\(\delta\)</span> preferable to <span class="math inline">\(\text{P}(X &gt; Y)\)</span> because of the possibility of ties.</p>
<p><strong>Buyse, M. (2010), “Generalized pairwise comparisons of prioritized outcomes in the two-sample problem,” <em>Statistics in Medicine</em>, 29, 3245–3257.</strong> Considered the “proportion in favor of treatment” <span class="math inline">\(\Delta = \text{P}(X &gt; Y) - \text{P}(Y &gt; X)\)</span> (conditional on <span class="math inline">\(X \ne Y\)</span>, though this wasn’t stated clearly) as a measure of treatment effect. For different types of univariate outcome, showed how testing for <span class="math inline">\(\Delta\)</span> relates to standard statistical tests. Proposed using <span class="math inline">\(\Delta\)</span> to compare several outcome variables simultaneously by prioritizing the outcomes, and thereby defining whether each possible comparison of outcomes is favorable, unfavorable, or neutral.</p>
</div>
<div id="connection-to-area-under-the-roc-above-the-od-curve" class="section level1">
<h1>Connection to area under the ROC (above the OD) curve</h1>
<p><strong>Bamber, D. (1975), “The area above the ordinal dominance graph and the area below the receiver operating characteristic graph,” <em>Journal of Mathematical Psychology</em>, 12, 387–415.</strong> Described how <span class="math inline">\(\text{P}(X &gt; Y) + \frac{1}{2}\text{P}(X = Y)\)</span> is equal to the area above the ordinal dominance (OD) graph, which plots <span class="math inline">\(\text{P}(X \leq c)\)</span> vs <span class="math inline">\(\text{P}(Y \leq c)\)</span>, and the area under the ROC graph, which plots <span class="math inline">\(\text{P}(X &gt; c)\)</span> vs <span class="math inline">\(\text{P}(Y &gt; c)\)</span>, assuming one uses the trapezoidal method to compute area.</p>
</div>
<div id="estimation" class="section level1">
<h1>Estimation</h1>
<p>Point estimates of <span class="math inline">\(\text{P}(X &gt; Y)\)</span> or related estimands generally are straight-forward. There appeared to be substantial literature about computing confidence intervals, which I don’t try to include here. One interesting estimation problem is when the outcomes <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are censored, as in the case of survival outcomes.</p>
<p><strong>Efron, B. (1976), “The two-sample problem with censored data,” <em>Proceedings of the Fifth Berkeley Symposium on Mathematical Statistics and Probability</em>, 4, 831–853.</strong> For the problem of performing generalized Wilcoxon rank-sum test, reviewed the proposals of Gehan (1965) and Gilbert (1962). Proposed an alternative, superior test statistic based on (essentially) Kaplan-Meier estimates of the two population cdfs. The test statistic represents an estimate of <span class="math inline">\(\text{P}(X \geq Y)\)</span>.</p>
</div>
<div id="adjusting-for-covariates" class="section level1">
<h1>Adjusting for covariates</h1>
<p>These two references are examples — I didn’t systematically search for related methods.</p>
<p><strong>Brumback, L. C., Pepe, M. S., and Alonzo, T. A. (2006), “Using the ROC curve for gauging treatment effect in clinical trials,” <em>Statistics in Medicine</em>, 25, 575–590.</strong> Adapted a method for ROC curve regression to provide a method for evaluating covariate-adjusted treatment effect in terms of a conditional <span class="math inline">\(\text{P}(X &gt; Y)\)</span>. The regression model was fit on pairs of individuals, and the interest was in conditioning on the individuals having the same covariate values.</p>
<p><strong>Thas, O., Neve, J. D., Clement, L., and Ottoy, J. P. (2012), “Probabilistic index models,” <em>Journal of the Royal Statistical Society: Series B</em>, 74, 623–671.</strong> Proposed a more general regression framework which extended the method of Brumback, Pepe, and Alonzo (2006).</p>
</div>
<div class="footnotes footnotes-end-of-document">
<hr />
<ol>
<li id="fn1"><p>Kruskal, W. H. (1957), “Historical notes on the Wilcoxon unpaired two-sample test,” <em>Journal of the American Statistical Association</em> 52(279), 356–360.<a href="#fnref1" class="footnote-back">↩︎</a></p></li>
<li id="fn2"><p>Ibid.<a href="#fnref2" class="footnote-back">↩︎</a></p></li>
<li id="fn3"><p>O’Brien, P. C. (1988), “Comparing two samples: Extensions of the <em>t</em>, rank-sum, and log-rank tests,” <em>Journal of the American Statistical Association</em>, 83(401), 52–61.<a href="#fnref3" class="footnote-back">↩︎</a></p></li>
<li id="fn4"><p>Senn, S. (2011), “U is for unease: Reasons for mistrusting overlap measures for reporting clinical trials,” <em>Statistics in Biopharmaceutical Research</em>, 3(2), 302–309.<a href="#fnref4" class="footnote-back">↩︎</a></p></li>
<li id="fn5"><p>Vargha, A., and Delaney, H. D. (1998), “The Kruskal-Wallis test and stochastic homogeneity,” <em>Journal of Educational and Behavioral Statistics</em>, 23(2), 170–192.<a href="#fnref5" class="footnote-back">↩︎</a></p></li>
<li id="fn6"><p>Greenland, S., Fay, M. P., Brittain, E. H., Shih, J. H., Follmann, D. A., Gabriel, E. E., and Robins, J. M. (2020), “On causal inferences for personalized medicine: How hidden causal assumptions led to erroneous causal claims about the D-value,” <em>The American Statistician</em>, 74(3), 243–248.<a href="#fnref6" class="footnote-back">↩︎</a></p></li>
<li id="fn7"><p>Kruskal, W. H. (1957).<a href="#fnref7" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
